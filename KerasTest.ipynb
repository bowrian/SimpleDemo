{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "a = tf.constant(10)\n",
    "b = tf.constant(20)\n",
    "print(sess.run(a+b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = Sequential([\n",
    "        #Dense(32,units = 784),\n",
    "        #Activation('relu'),\n",
    "        #Dense(10),\n",
    "        #Activation('softmax'),\n",
    "    #])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据类型输入 \n",
    "模型需要知道输入数据的shape，因此，Sequential的第一层需要接受一个关于输入数据shape的参数，后面的各个层则可以自动的推导出中间数据的shape，因此不需要为每个层都指定这个参数。有几种方法来为第一层指定输入数据的shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编译\n",
    "在训练模型之前，我们需要通过compile来对学习过程进行配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For a multi-class classification problem\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#For a binary classification problem\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#For a mean squared error regression problem\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'mse')\n",
    "\n",
    "#For custom metrics\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true,y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy',mean_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 训练\n",
    "keras以Numpy数组作为输入数据和标签的数据类型。训练类型一般使用fit函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.7086 - acc: 0.5070\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 68us/step - loss: 0.7006 - acc: 0.5150\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.6944 - acc: 0.5310\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 61us/step - loss: 0.6921 - acc: 0.5290\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6871 - acc: 0.5210\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.6839 - acc: 0.5560\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.6803 - acc: 0.5540\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.6776 - acc: 0.5750\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.6747 - acc: 0.5710\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.6702 - acc: 0.5880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x164b72460f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For a single-input model with 2 classes(binary classification):\n",
    "model = Sequential()\n",
    "model.add(Dense(32,activation = 'relu',input_dim = 100))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000,100))\n",
    "labels = np.random.randint(2,size = (1000,1))\n",
    "\n",
    "#Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data,labels,epochs = 10,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 324us/step - loss: 2.3455 - acc: 0.1030\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 2.3177 - acc: 0.1070\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 94us/step - loss: 2.3011 - acc: 0.1200\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.2855 - acc: 0.1280\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.2729 - acc: 0.1460\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 2.2612 - acc: 0.1480\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 2.2487 - acc: 0.1670\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 2.2393 - acc: 0.1680\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 2.2267 - acc: 0.1800\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 2.2177 - acc: 0.1790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x164b8761940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For a single-input model with 10 classes(categorical classification):\n",
    "model = Sequential()\n",
    "model.add(Dense(32,activation = 'relu',input_dim = 100))\n",
    "model.add(Dense(10,activation = 'softmax'))\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "#Generate dummy data\n",
    "import keras\n",
    "import numpy as np\n",
    "data = np.random.random((1000,100))\n",
    "labels = np.random.randint(10,size = (1000,1))\n",
    "\n",
    "#Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "#上一句中出现了keras名的命名错误，原因是没有导入keras包，所以在前面加上import keras即可解决错误\n",
    "#Train the model,iterating on the data in batches of 32 samples\n",
    "model.fit(data,one_hot_labels,epochs = 10,batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 基于多层感知器的softmax多分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 297us/step - loss: 2.4141 - acc: 0.0980\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3627 - acc: 0.0950\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.3346 - acc: 0.1130\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3337 - acc: 0.1070\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3348 - acc: 0.0930\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 2.3129 - acc: 0.1120\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.3222 - acc: 0.0920\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3058 - acc: 0.1260\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 2.3076 - acc: 0.1170\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 2.3036 - acc: 0.1110\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 2.2988 - acc: 0.1280\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 2.3065 - acc: 0.1100\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3070 - acc: 0.1270\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 2.2905 - acc: 0.1360\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 2.2934 - acc: 0.1240\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.3000 - acc: 0.1170\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3044 - acc: 0.1060\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 2.2963 - acc: 0.1260\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3069 - acc: 0.1110\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 2.2971 - acc: 0.1370\n",
      "100/100 [==============================] - 0s 731us/step\n"
     ]
    }
   ],
   "source": [
    "#Generate dummy data\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000,20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10,size=(1000,1)),num_classes=10)\n",
    "x_test = np.random.random((100,20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10,size=(100,1)),num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "#Dense(64) is a fully-connnected layer with 64 hidden units\n",
    "#in the first layer,you must specify the expected input data shape;\n",
    "#here,20-dimensional vectors\n",
    "\n",
    "model.add(Dense(64,activation = 'relu',input_dim = 20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr = 0.01,decay = 1e-6,momentum = 0.9,nesterov = True)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,epochs=20,batch_size=128)\n",
    "\n",
    "score = model.evaluate(x_test,y_test,batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### MLP的二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 0s 353us/step - loss: 0.7311 - acc: 0.5050\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.7215 - acc: 0.4920\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.7080 - acc: 0.5060\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.7080 - acc: 0.5060\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.7040 - acc: 0.5240\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.7045 - acc: 0.4980\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.7063 - acc: 0.4850\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.7041 - acc: 0.4910\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.6973 - acc: 0.5120\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 0.6997 - acc: 0.5000\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.6922 - acc: 0.5140\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.6943 - acc: 0.5150\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.7034 - acc: 0.5050\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.6946 - acc: 0.5180\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.6924 - acc: 0.5380\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 26us/step - loss: 0.6901 - acc: 0.5190\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.6957 - acc: 0.5170\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.6933 - acc: 0.5310\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.6931 - acc: 0.5250\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.6903 - acc: 0.5390\n",
      "100/100 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "#Generate dummy data\n",
    "x_train = np.random.random((1000,20))\n",
    "y_train = np.random.randint(2,size=(1000,1))\n",
    "\n",
    "x_test = np.random.random((100,20))\n",
    "y_test = np.random.randint(2,size=(100,1))\n",
    "\n",
    "model = Sequential()\n",
    "#model 为Sequential类实例化后的一个对象，然后在后面调用Sequential类的方法\n",
    "model.add(Dense(64,input_dim=20,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,epochs=20,batch_size=128)\n",
    "score = model.evaluate(x_test,y_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类似VGG的卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.3143\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 2.3238\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 2.2567\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 2.2300\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 2.2796\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 2.2666\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 2.2647\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 2.2372\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 2.2599\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 3s 30ms/step - loss: 2.2597\n",
      "20/20 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#Generate dummy data\n",
    "x_train = np.random.random((100,100,100,3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10,size=(100,1)),num_classes=10)\n",
    "x_test = np.random.random((20,100,100,3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10,size=(20,1)),num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "#input:100*100 image with 3 channels->(100,100,3)tensors\n",
    "#this applies 32 convolution filters of size 3*3 each\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(100,100,3)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01,decay=1e-6,momentum=0.9,nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd)\n",
    "model.fit(x_train,y_train,batch_size=32,epochs=10)\n",
    "score = model.evaluate(x_test,y_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用LSTM的序列分类 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-85a787acfc87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'max_features' is not defined"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,batch_size=16,epochs=10)\n",
    "score = model.evaluate(x_test,y_test,batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用ID卷积的序列分类 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-f5c36da31620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seq_length' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(seq_length, 100)))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
